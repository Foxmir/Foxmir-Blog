{"entries":[],"headings":["v1","v1-epsilon始终是最小值0.01epsilon-decay探索衰减指数过大导致衰减极快-但智能体一半回合时就触及最高分表明智能体的学习能力比预想更强","v1-r明显上升但loss和梯度范数同样上升合理现象","v2","v2-智能体明显提高探索率后相较于v1版r并没有显著提升v2提升的是学习能力不能和v1的随机好运对比问题前提错误","v3","v3-奖励函数呈现稳定学习到最高值后又迅速下降波动明显应该依靠稳定而非好运","v4","v4-典型的过冲-回落现象最大化偏差","v5","v5-图像概览","v5-对v4预期验证学习稳定性更佳达成了完整探索利用周期仍存在灾难性遗忘难以收敛到最优","v5-超长的中值平台稳定期更低学习率更大缓冲区带来的稳定性优势但同时也阻碍了向更高分的探索效率","v5-高值回落期超长平台期大缓冲区的信息滞后性带来的虚假稳定下的新旧数据碰撞","v5-最后阶段波动的归因长平台期带来的中值样本同质化随机性引入的糟糕样本混乱分布稳定在中值附近的癫狂","v5-处理与预期","v6","v6-图像概览","v6-对v5的验证高探索率带来高效学习缓冲区高质量样本分布帮助走出局部最优并托底","v6-上升学习期高学习率带来的理想上升期","v6-第一次高值回落期最优策略拟合的短暂平台期不可避免但毫不令人惊慌的灾难性遗忘必然的再次回升","v6-第二次高值回落期更加稳定且可靠的最优策略收敛脆弱性的持续存在预示了大方差跌落必然的再度回升","v6-处理和预期","v7-对照v5v6","v7-图像概览","v9达成单词模型完美收敛但不具有泛化性因为后期尝试泛化时运行次数过多而更改了系统流程"]}